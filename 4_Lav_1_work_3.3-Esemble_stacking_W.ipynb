{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af7d52e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11fe350a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7111a2d7-6de4-4bc2-b024-54ab56ea9eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r'data_output\\df_lav1.csv'\n",
    "df_lav1 = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3247138e-697c-423a-a70e-dce9249a0073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 104376 entries, 0 to 104375\n",
      "Data columns (total 15 columns):\n",
      " #   Column                                Non-Null Count   Dtype  \n",
      "---  ------                                --------------   -----  \n",
      " 0   Unnamed: 0                            104376 non-null  int64  \n",
      " 1   Anag_oc_sintesi_progetto              104376 non-null  object \n",
      " 2   Prog_OC_COD_CATEGORIA_SPESA           104376 non-null  object \n",
      " 3   Altr_CUP_COD_NATURA                   104376 non-null  int64  \n",
      " 4   Altr_CUP_COD_SETTORE                  104376 non-null  int64  \n",
      " 5   Altr_OC_COD_TIPO_AIUTO                104376 non-null  object \n",
      " 6   Sogg_OC_DENOM_PROGRAMMATORE           104376 non-null  object \n",
      " 7   Sogg_OC_DESCR_FORMA_GIU_BENEFICIARIO  104245 non-null  object \n",
      " 8   New_prj_duration_pred                 104376 non-null  int64  \n",
      " 9   New_marginal_cost                     104376 non-null  float64\n",
      " 10  New_DEN_REGIONE_new                   104376 non-null  object \n",
      " 11  New_DEN_PROVINCIA_new                 104376 non-null  object \n",
      " 12  New_DEN_COMUNE_new                    104376 non-null  object \n",
      " 13  New_Risk                              104376 non-null  int64  \n",
      " 14  Cluster_Comune                        99385 non-null   object \n",
      "dtypes: float64(1), int64(5), object(9)\n",
      "memory usage: 11.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df_lav1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ad078e3-f5e0-438e-90e8-a974afb8ad4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lav1 = df_lav1.drop(columns=[\"Unnamed: 0\",\"New_DEN_PROVINCIA_new\", \"New_marginal_cost\", \"Altr_CUP_COD_NATURA\", \"Altr_CUP_COD_SETTORE\",\"New_DEN_COMUNE_new\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fabb7f1-e585-4fde-a45b-0fa81616df57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorical_columns_to_force = ['Altr_CUP_COD_NATURA', 'Altr_CUP_COD_SETTORE', 'New_Risk']\n",
    "categorical_columns_to_force = ['New_Risk']\n",
    "\n",
    "df_lav1[categorical_columns_to_force] = df_lav1[categorical_columns_to_force].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fff3f1cb-499f-4dfe-aa1c-733b00a31f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifica i tipi di colonne\n",
    "text_cols = ['Anag_oc_sintesi_progetto', 'Sogg_OC_DESCR_FORMA_GIU_BENEFICIARIO','Sogg_OC_DENOM_PROGRAMMATORE']\n",
    "numeric_cols = ['New_prj_duration_pred', 'New_marginal_cost']\n",
    "#categorical_cols = list(set(X.columns) - set(text_cols) - set(numeric_cols))\n",
    "categorical_cols = list(set(df_lav1.columns) - set(numeric_cols)-set(text_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5149c621-52d2-4ae3-9884-7d5f2c63f18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_or_empty = df_lav1[text_cols].apply(lambda col: col.isna() | col.str.strip().eq(\"\"))\n",
    "df_lav1 = df_lav1[~nan_or_empty.any(axis=1)].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f788bfdc-fc22-4fc4-ad1b-e6e31280d752",
   "metadata": {},
   "source": [
    "### Dont consider invalid string for project description\n",
    "We consider that project description is an important features (confirmed by feature importance permutation) so because we have a big dataset we consider dont loosing information if we don consider rows with invalid string for project description, we made this applying the following funcion. From the following code we see that we have about 15 k record dont acceptable but all in class 0 --- the most unbalaced, so we accept to delete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb6ef772-2ff0-4ead-ad8f-2db75da87598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record con stringhe non accettabili nella colonna 'Anag_oc_sintesi_progetto':\n",
      "      Anag_oc_sintesi_progetto Prog_OC_COD_CATEGORIA_SPESA  \\\n",
      "3116                       M+M                         055   \n",
      "5275                       XXX                         001   \n",
      "34002                     ....                         051   \n",
      "34003                     ....                         051   \n",
      "34004                     ....                         051   \n",
      "...                        ...                         ...   \n",
      "74141                       SA                         067   \n",
      "74226                       SS                         067   \n",
      "75074                        G                         067   \n",
      "77539                        N                         067   \n",
      "85222                      VGM                         067   \n",
      "\n",
      "      Altr_OC_COD_TIPO_AIUTO Sogg_OC_DENOM_PROGRAMMATORE  \\\n",
      "3116                       F             REGIONE TOSCANA   \n",
      "5275                       D             REGIONE TOSCANA   \n",
      "34002                      F             MIUR ISTRUZIONE   \n",
      "34003                      F             MIUR ISTRUZIONE   \n",
      "34004                      F             MIUR ISTRUZIONE   \n",
      "...                      ...                         ...   \n",
      "74141                      B              REGIONE PUGLIA   \n",
      "74226                      B              REGIONE PUGLIA   \n",
      "75074                      B              REGIONE PUGLIA   \n",
      "77539                      B              REGIONE PUGLIA   \n",
      "85222                      B              REGIONE PUGLIA   \n",
      "\n",
      "        Sogg_OC_DESCR_FORMA_GIU_BENEFICIARIO  New_prj_duration_pred  \\\n",
      "3116                                  Comune                   1845   \n",
      "5275       Societa a responsabilita limitata                    686   \n",
      "34002                                 Comune                    188   \n",
      "34003                                 Comune                    219   \n",
      "34004                                 Comune                    172   \n",
      "...                                      ...                    ...   \n",
      "74141  Imprenditore individuale non agricolo                    483   \n",
      "74226  Imprenditore individuale non agricolo                    477   \n",
      "75074  Imprenditore individuale non agricolo                    471   \n",
      "77539  Imprenditore individuale non agricolo                    441   \n",
      "85222      Societa a responsabilita limitata                    561   \n",
      "\n",
      "      New_DEN_REGIONE_new New_Risk Cluster_Comune  \n",
      "3116              TOSCANA        0     Bet_5K_20K  \n",
      "5275              TOSCANA        0     Bet_5K_20K  \n",
      "34002             ABRUZZO        0      Less_2.5K  \n",
      "34003             ABRUZZO        0     Bet_5K_20K  \n",
      "34004             ABRUZZO        0      Less_2.5K  \n",
      "...                   ...      ...            ...  \n",
      "74141              PUGLIA        0     Bet_5K_20K  \n",
      "74226              PUGLIA        0    Bet_20K_50K  \n",
      "75074              PUGLIA        0      Less_2.5K  \n",
      "77539              PUGLIA        3     Bet_5K_20K  \n",
      "85222              PUGLIA        0      More_250K  \n",
      "\n",
      "[15393 rows x 9 columns]\n",
      "Numero di record con stringhe non accettabili: 15393\n",
      "Numero di categorie target impattate: 3\n",
      "Conteggio dei record impattati per categoria target:\n",
      "New_Risk\n",
      "0    15352\n",
      "3       39\n",
      "1        2\n",
      "2        0\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Funzione per identificare stringhe non accettabili\n",
    "def is_invalid_string(text):\n",
    "    if pd.isna(text):  # Controllo per NaN\n",
    "        return True\n",
    "    text = text.strip()  # Rimuove spazi iniziali e finali\n",
    "    # Controlla se il testo Ã¨ vuoto, troppo corto o ha solo caratteri non significativi\n",
    "    return len(text) < 4 or re.fullmatch(r\"[.]+\", text) is not None\n",
    "\n",
    "# Applica il filtro alla colonna 'Anag_oc_sintesi_progetto'\n",
    "invalid_rows = df_lav1[\"Anag_oc_sintesi_progetto\"].apply(is_invalid_string)\n",
    "\n",
    "# Seleziona i record con stringhe non accettabili\n",
    "invalid_records = df_lav1[invalid_rows]\n",
    "\n",
    "# Conta il numero di categorie target impattate\n",
    "categories_impacted = invalid_records[\"New_Risk\"].nunique()  # Sostituisci 'target' con il nome della tua colonna target\n",
    "\n",
    "# Conta le occorrenze per ogni categoria\n",
    "categories_count = invalid_records[\"New_Risk\"].value_counts()\n",
    "\n",
    "# Stampa i risultati\n",
    "print(\"Record con stringhe non accettabili nella colonna 'Anag_oc_sintesi_progetto':\")\n",
    "print(invalid_records)\n",
    "print(f\"Numero di record con stringhe non accettabili: {len(invalid_records)}\")\n",
    "print(f\"Numero di categorie target impattate: {categories_impacted}\")\n",
    "print(\"Conteggio dei record impattati per categoria target:\")\n",
    "print(categories_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1852e526-3dba-4cc9-a890-640e84385f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lav1 = df_lav1[~invalid_rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f8dffda-992f-4844-921f-473961ed64cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 88852 entries, 0 to 104375\n",
      "Data columns (total 9 columns):\n",
      " #   Column                                Non-Null Count  Dtype   \n",
      "---  ------                                --------------  -----   \n",
      " 0   Anag_oc_sintesi_progetto              88852 non-null  object  \n",
      " 1   Prog_OC_COD_CATEGORIA_SPESA           88852 non-null  object  \n",
      " 2   Altr_OC_COD_TIPO_AIUTO                88852 non-null  object  \n",
      " 3   Sogg_OC_DENOM_PROGRAMMATORE           88852 non-null  object  \n",
      " 4   Sogg_OC_DESCR_FORMA_GIU_BENEFICIARIO  88852 non-null  object  \n",
      " 5   New_prj_duration_pred                 88852 non-null  int64   \n",
      " 6   New_DEN_REGIONE_new                   88852 non-null  object  \n",
      " 7   New_Risk                              88852 non-null  category\n",
      " 8   Cluster_Comune                        84408 non-null  object  \n",
      "dtypes: category(1), int64(1), object(7)\n",
      "memory usage: 6.2+ MB\n"
     ]
    }
   ],
   "source": [
    "#df_lav1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e991fa3d-726c-40fa-b25f-91b8a03f1e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_lav1.drop('New_Risk', axis=1)\n",
    "y = df_lav1['New_Risk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f293ae7-c15b-4293-ad5d-378903d8b627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat it here to apply on the X with no target in\n",
    "text_cols = ['Anag_oc_sintesi_progetto', 'Sogg_OC_DESCR_FORMA_GIU_BENEFICIARIO','Sogg_OC_DENOM_PROGRAMMATORE']\n",
    "numeric_cols = ['New_prj_duration_pred']\n",
    "#categorical_cols = list(set(X.columns) - set(text_cols) - set(numeric_cols))\n",
    "categorical_cols = list(set(X.columns) - set(numeric_cols)-set(text_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f010371-8146-4f96-bb01-65469dd79ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 88852 entries, 0 to 104375\n",
      "Data columns (total 8 columns):\n",
      " #   Column                                Non-Null Count  Dtype \n",
      "---  ------                                --------------  ----- \n",
      " 0   Anag_oc_sintesi_progetto              88852 non-null  object\n",
      " 1   Prog_OC_COD_CATEGORIA_SPESA           88852 non-null  object\n",
      " 2   Altr_OC_COD_TIPO_AIUTO                88852 non-null  object\n",
      " 3   Sogg_OC_DENOM_PROGRAMMATORE           88852 non-null  object\n",
      " 4   Sogg_OC_DESCR_FORMA_GIU_BENEFICIARIO  88852 non-null  object\n",
      " 5   New_prj_duration_pred                 88852 non-null  int64 \n",
      " 6   New_DEN_REGIONE_new                   88852 non-null  object\n",
      " 7   Cluster_Comune                        84408 non-null  object\n",
      "dtypes: int64(1), object(7)\n",
      "memory usage: 6.1+ MB\n"
     ]
    }
   ],
   "source": [
    "#X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66f0dc5-33c7-453f-9a26-e9b6e92f4671",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4eed3749-59c4-47da-bd34-c810e3954317",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_transformers = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('text1', TfidfVectorizer(), 'Anag_oc_sintesi_progetto'),\n",
    "        ('text2', TfidfVectorizer(), 'Sogg_OC_DESCR_FORMA_GIU_BENEFICIARIO'),\n",
    "        ('text3', TfidfVectorizer(), 'Sogg_OC_DENOM_PROGRAMMATORE')\n",
    "    ],\n",
    "    remainder='passthrough'  # Keep numeric and categorical data untouched\n",
    ")\n",
    "\n",
    "# Preprocessor for numeric and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols),\n",
    "    ],\n",
    "    remainder='drop'  # Drop columns not explicitly mentioned\n",
    ")\n",
    "\n",
    "# Combine preprocessing for numeric/categorical and text columns\n",
    "final_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num_cat', preprocessor, numeric_cols + categorical_cols),\n",
    "        ('text', text_transformers, text_cols),\n",
    "    ],\n",
    "    remainder='drop'  # Drop other columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5685d18d-0d31-4346-8415-20214cf43f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Index: 88852 entries, 0 to 104375\n",
      "Series name: New_Risk\n",
      "Non-Null Count  Dtype   \n",
      "--------------  -----   \n",
      "88852 non-null  category\n",
      "dtypes: category(1)\n",
      "memory usage: 781.1 KB\n"
     ]
    }
   ],
   "source": [
    "y.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ea5c913-9eb3-48df-a798-efedb7bc945d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# all X and y\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99859a93-8adb-42a8-b0c3-93f69df93431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Index: 62196 entries, 97842 to 28320\n",
      "Series name: New_Risk\n",
      "Non-Null Count  Dtype   \n",
      "--------------  -----   \n",
      "62196 non-null  category\n",
      "dtypes: category(1)\n",
      "memory usage: 546.8 KB\n"
     ]
    }
   ],
   "source": [
    "y_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "573848d5-9c0c-4337-a5f1-e78dd388d7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19d9f5f-ae94-4bfd-a0f3-3cec6f52fffd",
   "metadata": {},
   "source": [
    "# Apply Esemble stacking Model with:\n",
    "- weight balancing: function of frequences\n",
    "- thresholds = {0: 0.65, 1: 0.3, 2: 0.3, 3: 0.45} -- selected after several test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e9bb1821-34e9-46f9-9418-75b53a1ab2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed Class Weights: {0: 0.32178555907369466, 1: 4.613946587537092, 2: 5.367276492923714, 3: 2.043769716088328}\n",
      "Stacking Classifier Results:\n",
      "Accuracy: 0.6535\n",
      "F1 Score (macro): 0.5103\n",
      "\n",
      "Per-Class Metrics:\n",
      "Class 0:\n",
      "  Precision: 0.9680\n",
      "  Recall:    0.6264\n",
      "  F1-Score:  0.7606\n",
      "------------------------------\n",
      "Class 1:\n",
      "  Precision: 0.2153\n",
      "  Recall:    0.5308\n",
      "  F1-Score:  0.3064\n",
      "------------------------------\n",
      "Class 2:\n",
      "  Precision: 0.2463\n",
      "  Recall:    0.7720\n",
      "  F1-Score:  0.3735\n",
      "------------------------------\n",
      "Class 3:\n",
      "  Precision: 0.4691\n",
      "  Recall:    0.8350\n",
      "  F1-Score:  0.6007\n",
      "------------------------------\n",
      "\n",
      "Full Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.63      0.76     20710\n",
      "           1       0.22      0.53      0.31      1445\n",
      "           2       0.25      0.77      0.37      1241\n",
      "           3       0.47      0.83      0.60      3260\n",
      "\n",
      "    accuracy                           0.65     26656\n",
      "   macro avg       0.47      0.69      0.51     26656\n",
      "weighted avg       0.83      0.65      0.70     26656\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "rf_model_path = r'C:\\Users\\gsepe\\Capstone_Prj\\data_output\\Lav_1_work_3.3-RF_W_BM.pkl'\n",
    "lr_model_path = r'C:\\Users\\gsepe\\Capstone_Prj\\data_output\\Lav_1_work_3.3-LR_W_BM.pkl'\n",
    "\n",
    "\n",
    "# Load the best estimators from pickled files\n",
    "with open(rf_model_path, 'rb') as rf_file:\n",
    "    best_rf_model = joblib.load(rf_file)\n",
    "\n",
    "with open(lr_model_path, 'rb') as lr_file:\n",
    "    best_lr_model = joblib.load(lr_file)\n",
    "\n",
    "# Define thresholds for each class\n",
    "thresholds = {0: 0.65, 1: 0.3, 2: 0.3, 3: 0.45}\n",
    "\n",
    "# Compute class weights dynamically using compute_class_weight\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "weights_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
    "\n",
    "print(f\"Computed Class Weights: {weights_dict}\")\n",
    "\n",
    "# Modify predictions based on thresholds\n",
    "def apply_thresholds(probabilities, thresholds):\n",
    "\n",
    "    adjusted_preds = np.zeros(probabilities.shape[0], dtype=int)\n",
    "    for class_idx, threshold in thresholds.items():\n",
    "        adjusted_preds[probabilities[:, class_idx] >= threshold] = class_idx\n",
    "    return adjusted_preds\n",
    "\n",
    "# Base models\n",
    "base_models = [\n",
    "    ('rf', best_rf_model),  \n",
    "    ('lr', best_lr_model)   \n",
    "]\n",
    "\n",
    "# Meta-model \n",
    "meta_model = LogisticRegression(random_state=42, class_weight=weights_dict)\n",
    "\n",
    "# Stacking classifier\n",
    "stacking_classifier = StackingClassifier(\n",
    "    estimators=base_models,        \n",
    "    final_estimator=meta_model,    \n",
    "    cv=5,                          \n",
    "    n_jobs=-1                      \n",
    ")\n",
    "\n",
    "# Fit the stacking classifier\n",
    "stacking_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities for the test set\n",
    "probabilities = stacking_classifier.predict_proba(X_test)\n",
    "\n",
    "# Apply thresholds to get adjusted class predictions\n",
    "y_pred = apply_thresholds(probabilities, thresholds)\n",
    "\n",
    "# Evaluate overall performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# Evaluate per-class metrics\n",
    "precision_per_class = precision_score(y_test, y_pred, average=None)\n",
    "recall_per_class = recall_score(y_test, y_pred, average=None)\n",
    "f1_per_class = f1_score(y_test, y_pred, average=None)\n",
    "\n",
    "# Display the overall results\n",
    "print(\"Stacking Classifier Results:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1 Score (macro): {f1_macro:.4f}\\n\")\n",
    "\n",
    "# Display per-class results\n",
    "print(\"Per-Class Metrics:\")\n",
    "for class_idx in range(len(precision_per_class)):\n",
    "    print(f\"Class {class_idx}:\")\n",
    "    print(f\"  Precision: {precision_per_class[class_idx]:.4f}\")\n",
    "    print(f\"  Recall:    {recall_per_class[class_idx]:.4f}\")\n",
    "    print(f\"  F1-Score:  {f1_per_class[class_idx]:.4f}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "# Full classification report for reference\n",
    "print(\"\\nFull Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b20f0c51-58e7-47ff-9c03-0bd3784e2bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_model_bm_path = r\"data_output\\Lav_1_work_3.3-Esemble_W_BM.pkl\"\n",
    "joblib.dump(stacking_classifier, ensemble_model_bm_path)\n",
    "\n",
    "# Save the results (metrics) to a dictionary\n",
    "results = {\n",
    "    \"accuracy\": accuracy,\n",
    "    \"f1_macro\": f1_macro,\n",
    "    \"precision_per_class\": precision_per_class.tolist(),\n",
    "    \"recall_per_class\": recall_per_class.tolist(),\n",
    "    \"f1_per_class\": f1_per_class.tolist(),\n",
    "    \"classification_report\": classification_report(y_test, y_pred, output_dict=True)\n",
    "}\n",
    "\n",
    "# Save results as a pickle file\n",
    "results_path = r\"data_output\\Lav_1_work_3.3-Esemble_W.pkl\"\n",
    "with open(results_path, 'wb') as results_file:\n",
    "    joblib.dump(results, results_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
